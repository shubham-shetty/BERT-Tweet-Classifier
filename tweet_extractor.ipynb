{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286fb9a5",
   "metadata": {},
   "source": [
    "# Scraping Twitter for Hate Speech\n",
    "The task at hand is to build a dataset of tweets for hate speech classification using NLP methods. For this purpose, I've written a generic Tweet scraper code using Tweepy to pull tweets based on a search query and store as a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16794fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install Tweepy if you don't already have the package\n",
    "# !pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to place config.ini in location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2145818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping_utils import scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e12d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4f0d655",
   "metadata": {},
   "source": [
    "## Pulling Tweets based on Key Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eccec803",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_queries = [\"muslim\",\"hindu\",\"sikh\",\"hate+asians\"]\n",
    "count = 20\n",
    "for q in text_queries:\n",
    "    scraper.get_tweets_by_query(q, count, filename = f\"trial_{q}\", result_type=\"mixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a01bd",
   "metadata": {},
   "source": [
    "## Pulling Tweets based on Usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b578c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = [\"JoeBiden\", \"BarackObama\", \"SenSanders\", \"LeaderMcConnell\", \"SpeakerRyan\", \"Mike_Pence\"]\n",
    "female = [\"HillaryClinton\", \"NikkiHaley\", \"AOC\", \"KamalaHarris\", \"SpeakerPelosi\", \"RashidaTlaib\"]\n",
    "count = 20\n",
    "male_df = pd.DataFrame()\n",
    "female_df = pd.DataFrame()\n",
    "for u in male:\n",
    "    male_df = male_df.append(scraper.get_tweets_by_user(username=u, count=count))\n",
    "for u in female:\n",
    "    female_df = female_df.append(scraper.get_tweets_by_user(username=u, count=count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b550f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df.to_csv(f'{OUTPUT_DIR}/male_tweets.txt', sep=',', index = False)\n",
    "female_df.to_csv(f'{OUTPUT_DIR}/female_tweets.txt', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a1c5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Scraper for Hate Speech detection\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import time\n",
    "import configparser\n",
    "\n",
    "# Folder Locations\n",
    "OUTPUT_DIR = \"data\"\n",
    "\n",
    "# Load Configs\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "consumer_key = config.get('dev', 'consumer_key')\n",
    "consumer_secret = config.get('dev', 'consumer_secret')\n",
    "access_token = config.get('dev', 'access_token')\n",
    "access_token_secret = config.get('dev', 'access_token_secret')\n",
    "\n",
    "# Grant Twitter dev account access to Tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6dc1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = [\"LarrySabato\",\"Redistrict\",\"NateSilver538\",\"ScottWRasmussen\",\"EWErickson\",\"stevebenen\"]\n",
    "female = [\"donnabrazile\",\"anamariecox\",\"LizMair\",\"mindyfinn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f7fe35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for username in male:\n",
    "    # Creation of query method using parameters\n",
    "    tweets = tweepy.Cursor(api.user_timeline,screen_name=username, include_rts=False, tweet_mode = 'extended').items(count)\n",
    "\n",
    "    # Pulling information from tweets iterable object\n",
    "    tweets_list = [[tweet.created_at, tweet.id, tweet.full_text] for tweet in tweets]\n",
    "\n",
    "    # Creation of dataframe from tweets list\n",
    "    # Add or remove columns as you remove tweet information\n",
    "    tweets_df = pd.DataFrame(tweets_list,columns=['Datetime', 'Tweet Id', 'Text'])\n",
    "    tweets_df.to_csv(f'data/file_{username}.txt', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f0d56c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for username in female:\n",
    "    # Creation of query method using parameters\n",
    "    tweets = tweepy.Cursor(api.user_timeline,screen_name=username, include_rts=False, tweet_mode = 'extended').items(count)\n",
    "\n",
    "    # Pulling information from tweets iterable object\n",
    "    tweets_list = [[tweet.created_at, tweet.id, tweet.full_text] for tweet in tweets]\n",
    "\n",
    "    # Creation of dataframe from tweets list\n",
    "    # Add or remove columns as you remove tweet information\n",
    "    tweets_df = pd.DataFrame(tweets_list,columns=['Datetime', 'Tweet Id', 'Text'])\n",
    "    tweets_df.to_csv(f'data/file_{username}.txt', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552dc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
